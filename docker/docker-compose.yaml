services:
  zookeeper:
    container_name: des_zookeeper
    image: confluentinc/cp-zookeeper:6.2.1
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - des_network

  kafka:
    container_name: des_kafka
    image: confluentinc/cp-kafka:6.2.1
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: des_zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://des_kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - des_network

  kafka-ui:
    container_name: des_kafka_ui
    image: provectuslabs/kafka-ui:latest
    environment:
      - KAFKA_CLUSTERS_0_NAME=des-cluster
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=des_kafka:9092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=des_zookeeper:2181
    ports:
      - "8085:8080"
    depends_on:
      - kafka
      - zookeeper
    networks:
      - des_network

  neo4j:
    container_name: des_neo4j
    image: neo4j:5.12.0
    environment:
      - NEO4J_AUTH=none
    ports:
      - "7475:7474"
      - "7688:7687"
    volumes:
      - neo4j_data:/data
    networks:
      - des_network

  # spark-master:
  #   image: apache/spark:3.5.0
  #   container_name: des_spark-master
  #   hostname: spark-master
  #   command: >
  #     bash -c "
  #     apt-get update && apt-get install -y python3 python3-pip &&
  #     pip3 install -r /opt/spark-apps/requirements.txt &&
  #     /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
  #     "
  #   environment:
  #     SPARK_MODE: master
  #     SPARK_MASTER_HOST: spark-master
  #     SPARK_MASTER_PORT: 7077
  #     SPARK_MASTER_WEBUI_PORT: 8080
  #     SPARK_METRICS_CONF: /opt/spark/conf/metrics.properties
  #     SPARK_WORKER_CORES: 2
  #     SPARK_WORKER_MEMORY: 2g
  #     SPARK_WORKER_WEBUI_PORT: 8081
  #   user: root 
  #   ports:
  #     - '8080:8080'   # Spark master UI + metrics
  #     - '7077:7077'   # Spark master port
  #     - '8000:8000'   # Python app Prometheus metrics
  #     - '4040:4040'   # Spark driver UI for local mode
  #   volumes:
  #     - ./spark-apps:/opt/spark-apps
  #     - ../data:/opt/spark-data/data
  #     - ./spark-metrics/metrics.properties:/opt/spark/conf/metrics.properties
  #   networks:
  #     - des_network

  des_prometheus:
    image: prom/prometheus:latest
    container_name: des_prometheus
    volumes:
      - ../prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - des_network
    restart: always

  des_grafana:
    image: grafana/grafana:latest
    container_name: des_grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ../grafana-data:/var/lib/grafana
    networks:
      - des_network
    depends_on:
      - des_prometheus
    restart: always

volumes:
  neo4j_data:
  kafka_data:

networks:
  des_network:
    driver: bridge
